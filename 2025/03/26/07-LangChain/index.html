<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="07-LangChain, Blog">
    <meta name="description" content="1 LangChain 的核心组件
模型 I&amp;#x2F;O 封装
LLMs：大语言模型
Chat Models：一般基于 LLMs，但按对话结构重新封装
PromptTemple：提示词模板
OutputParser：解析输出


数据连接">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>07-LangChain | Blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Blog</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/TangCharlotte/AI-Classes" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/TangCharlotte/AI-Classes" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">07-LangChain</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2025-03-26
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="1-LangChain-的核心组件"><a href="#1-LangChain-的核心组件" class="headerlink" title="1 LangChain 的核心组件"></a>1 LangChain 的核心组件</h2><ol>
<li>模型 I&#x2F;O 封装<ol>
<li>LLMs：大语言模型</li>
<li>Chat Models：一般基于 LLMs，但按对话结构重新封装</li>
<li>PromptTemple：提示词模板</li>
<li>OutputParser：解析输出</li>
</ol>
</li>
<li>数据连接封装<ol>
<li>Document Loaders：各种格式文件的加载器</li>
<li>Document Transformers：对文档的常用操作，如：split, filter, translate, extract metadata, etc</li>
<li>Text Embedding Models：文本向量化表示，用于检索等操作（啥意思？别急，后面详细讲）</li>
<li>Verctorstores: （面向检索的）向量的存储</li>
<li>Retrievers: 向量的检索</li>
</ol>
</li>
<li>对话历史管理<ol>
<li>对话历史的存储、加载与剪裁</li>
</ol>
</li>
<li>架构封装<ol>
<li>Chain：实现一个功能或者一系列顺序功能组合</li>
<li>Agent：根据用户输入，自动规划执行步骤，自动选择每步需要的工具，最终完成用户指定的功能<ul>
<li>Tools：调用外部功能的函数，例如：调 google 搜索、文件 I&#x2F;O、Linux Shell 等等</li>
<li>Toolkits：操作某软件的一组工具集，例如：操作 DB、操作 Gmail 等等</li>
</ul>
</li>
</ol>
</li>
<li>Callbacks</li>
</ol>
<img src="/2025/03/26/07-LangChain/1742985220520-5.png" class="">

<h3 id="文档（以-Python-版为例）"><a href="#文档（以-Python-版为例）" class="headerlink" title="文档（以 Python 版为例）"></a>文档（以 Python 版为例）</h3><ul>
<li>功能模块：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/get_started/introduction">https://python.langchain.com/docs/get_started/introduction</a></li>
<li>API 文档：<a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/langchain_api_reference.html">https://api.python.langchain.com/en/latest/langchain_api_reference.html</a></li>
<li>三方组件集成：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/integrations/platforms/">https://python.langchain.com/docs/integrations/platforms/</a></li>
<li>官方应用案例：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/use_cases">https://python.langchain.com/docs/use_cases</a></li>
<li>调试部署等指导：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/guides/debugging">https://python.langchain.com/docs/guides/debugging</a></li>
</ul>
<h2 id="2-模型-I-O-封装"><a href="#2-模型-I-O-封装" class="headerlink" title="2 模型 I&#x2F;O 封装"></a>2 模型 I&#x2F;O 封装</h2><p>把不同的模型，统一封装成一个接口，方便更换模型而不用重构代码。</p>
<h3 id="2-1-模型-API：LLM-vs-ChatModel"><a href="#2-1-模型-API：LLM-vs-ChatModel" class="headerlink" title="2.1 模型 API：LLM vs. ChatModel"></a>2.1 模型 API：LLM vs. ChatModel</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !pip install --upgrade langchain</span></span><br><span class="line"><span class="comment"># !pip install --upgrade langchain-openai</span></span><br><span class="line"><span class="comment"># !pip install --upgrade langchain-community</span></span><br></pre></td></tr></table></figure>

<h4 id="2-1-1-OpenAI-模型封装"><a href="#2-1-1-OpenAI-模型封装" class="headerlink" title="2.1.1 OpenAI 模型封装"></a>2.1.1 OpenAI 模型封装</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>)  <span class="comment"># 默认是gpt-3.5-turbo</span></span><br><span class="line">response = llm.invoke(<span class="string">&quot;你是谁&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>我是一个人工智能助手，旨在回答问题和提供信息。如果你有任何问题或需要帮助，尽管问我吧！</p>
</blockquote>
<h4 id="2-1-2-多轮对话-Session-封装"><a href="#2-1-2-多轮对话-Session-封装" class="headerlink" title="2.1.2 多轮对话 Session 封装"></a>2.1.2 多轮对话 Session 封装</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> (</span><br><span class="line">    AIMessage,  <span class="comment"># 等价于OpenAI接口中的assistant role</span></span><br><span class="line">    HumanMessage,  <span class="comment"># 等价于OpenAI接口中的user role</span></span><br><span class="line">    SystemMessage  <span class="comment"># 等价于OpenAI接口中的system role</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(content=<span class="string">&quot;你是AGIClass的课程助理。&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;我是学员，我叫王。&quot;</span>),</span><br><span class="line">    AIMessage(content=<span class="string">&quot;欢迎！&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;我是谁&quot;</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">ret = llm.invoke(messages)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ret.content)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>你是学员王。有什么我可以帮助你的吗？</p>
</blockquote>
<p><strong>划重点：</strong>通过模型封装，实现不同模型的统一接口调用</p>
<h4 id="2-1-3-换个国产模型"><a href="#2-1-3-换个国产模型" class="headerlink" title="2.1.3 换个国产模型"></a>2.1.3 换个国产模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !pip install qianfan</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其它模型分装在 langchain_community 底包中</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models <span class="keyword">import</span> QianfanChatEndpoint</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">llm = QianfanChatEndpoint(</span><br><span class="line">    qianfan_ak=os.getenv(<span class="string">&#x27;ERNIE_CLIENT_ID&#x27;</span>),</span><br><span class="line">    qianfan_sk=os.getenv(<span class="string">&#x27;ERNIE_CLIENT_SECRET&#x27;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;介绍一下你自己&quot;</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">ret = llm.invoke(messages)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ret.content)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[INFO][2024-08-20 12:16:42.297] oauth.py:228 [t:140521157437248]: trying to refresh access_token for ak <code>cuTPS7***</code></p>
<p>[INFO][2024-08-20 12:16:43.110] oauth.py:243 [t:140521157437248]: sucessfully refresh access_token</p>
<p>您好，我是文心一言，英文名是ERNIE Bot。我能够与人对话互动，回答问题，协助创作，高效便捷地帮助人们获取信息、知识和灵感。</p>
</blockquote>
<h3 id="2-2-模型的输入与输出"><a href="#2-2-模型的输入与输出" class="headerlink" title="2.2 模型的输入与输出"></a>2.2 模型的输入与输出</h3><img src="/2025/03/26/07-LangChain/1742985220519-1.jpeg" class="">

<h4 id="2-2-1-Prompt-模板封装"><a href="#2-2-1-Prompt-模板封装" class="headerlink" title="2.2.1 Prompt 模板封装"></a>2.2.1 Prompt 模板封装</h4><ol>
<li>PromptTemplate 可以在模板中自定义变量</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">template = PromptTemplate.from_template(<span class="string">&quot;给我讲个关于&#123;subject&#125;的笑话&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===Template===&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(template)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===Prompt===&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(template.<span class="built_in">format</span>(subject=<span class="string">&#x27;小明&#x27;</span>))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>&#x3D;&#x3D;&#x3D;Template&#x3D;&#x3D;&#x3D;</p>
<p>input_variables&#x3D;[‘subject’] template&#x3D;’给我讲个关于{subject}的笑话’</p>
<p>&#x3D;&#x3D;&#x3D;Prompt&#x3D;&#x3D;&#x3D;</p>
<p>给我讲个关于小明的笑话</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 LLM</span></span><br><span class="line">llm = ChatOpenAI()</span><br><span class="line"><span class="comment"># 通过 Prompt 调用 LLM</span></span><br><span class="line">ret = llm.invoke(template.<span class="built_in">format</span>(subject=<span class="string">&#x27;小明&#x27;</span>))</span><br><span class="line"><span class="comment"># 打印输出</span></span><br><span class="line"><span class="built_in">print</span>(ret.content)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>好的，这里有一个关于小明的笑话：</p>
<p>小明去看医生，医生问道：“小明，你为什么老是摔倒？” 小明回答道：“因为我从来不看地上。” 想不到小明的回答这么直接，医生忍不住笑了出来。</p>
</blockquote>
<ol>
<li>ChatPromptTemplate 用模板表示的对话上下文</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">    SystemMessagePromptTemplate,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">template = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        SystemMessagePromptTemplate.from_template(</span><br><span class="line">            <span class="string">&quot;你是&#123;product&#125;的客服助手。你的名字叫&#123;name&#125;&quot;</span>),</span><br><span class="line">        HumanMessagePromptTemplate.from_template(<span class="string">&quot;&#123;query&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI()</span><br><span class="line">prompt = template.format_messages(</span><br><span class="line">    product=<span class="string">&quot;AGI课堂&quot;</span>,</span><br><span class="line">    name=<span class="string">&quot;瓜瓜&quot;</span>,</span><br><span class="line">    query=<span class="string">&quot;你是谁&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(prompt)</span><br><span class="line"></span><br><span class="line">ret = llm.invoke(prompt)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ret.content)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[SystemMessage(content&#x3D;’你是AGI课堂的客服助手。你的名字叫瓜瓜’), HumanMessage(content&#x3D;’你是谁’)]</p>
<p>我是AGI课堂的客服助手，我的名字叫瓜瓜。有什么可以帮助你的吗？</p>
</blockquote>
<ol>
<li>MessagesPlaceholder 把多轮对话变成模板</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">    MessagesPlaceholder,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">human_prompt = <span class="string">&quot;Translate your answer to &#123;language&#125;.&quot;</span></span><br><span class="line">human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)</span><br><span class="line"></span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    <span class="comment"># variable_name 是 message placeholder 在模板中的变量名</span></span><br><span class="line">    <span class="comment"># 用于在赋值时使用</span></span><br><span class="line">    [MessagesPlaceholder(<span class="string">&quot;history&quot;</span>), human_message_template]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> AIMessage, HumanMessage</span><br><span class="line"></span><br><span class="line">human_message = HumanMessage(content=<span class="string">&quot;Who is Elon Musk?&quot;</span>)</span><br><span class="line">ai_message = AIMessage(</span><br><span class="line">    content=<span class="string">&quot;Elon Musk is a billionaire entrepreneur, inventor, and industrial designer&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">messages = chat_prompt.format_prompt(</span><br><span class="line">    <span class="comment"># 对 &quot;history&quot; 和 &quot;language&quot; 赋值</span></span><br><span class="line">    history=[human_message, ai_message], language=<span class="string">&quot;中文&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(messages.to_messages())</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[HumanMessage(content&#x3D;’Who is Elon Musk?’), AIMessage(content&#x3D;’Elon Musk is a billionaire entrepreneur, inventor, and industrial designer’), HumanMessage(content&#x3D;’Translate your answer to 中文.’)]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = llm.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(result.content)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>埃隆·马斯克是一位亿万富翁企业家、发明家和工业设计师。</p>
</blockquote>
<p><strong>划重点：</strong>把Prompt模板看作带有参数的函数</p>
<h4 id="2-2-2-从文件加载-Prompt-模板"><a href="#2-2-2-从文件加载-Prompt-模板" class="headerlink" title="2.2.2 从文件加载 Prompt 模板"></a>2.2.2 从文件加载 Prompt 模板</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">template = PromptTemplate.from_file(<span class="string">&quot;example_prompt_template.txt&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===Template===&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(template)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===Prompt===&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(template.<span class="built_in">format</span>(topic=<span class="string">&#x27;黑色幽默&#x27;</span>))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>&#x3D;&#x3D;&#x3D;Template&#x3D;&#x3D;&#x3D;</p>
<p>input_variables&#x3D;[‘topic’] template&#x3D;’举一个关于{topic}的例子’</p>
<p>&#x3D;&#x3D;&#x3D;Prompt&#x3D;&#x3D;&#x3D;</p>
<p>举一个关于黑色幽默的例子</p>
</blockquote>
<h3 id="2-3-结构化输出"><a href="#2-3-结构化输出" class="headerlink" title="2.3 结构化输出"></a>2.3 结构化输出</h3><h4 id="2-3-1-直接输出-Pydantic-对象"><a href="#2-3-1-直接输出-Pydantic-对象" class="headerlink" title="2.3.1 直接输出 Pydantic 对象"></a>2.3.1 直接输出 Pydantic 对象</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line"># 定义你的输出对象</span><br><span class="line">class <span class="type">Date</span>(BaseModel):</span><br><span class="line">    <span class="keyword">year</span>: <span class="type">int</span> <span class="operator">=</span> Field(description<span class="operator">=</span>&quot;Year&quot;)</span><br><span class="line">    <span class="keyword">month</span>: <span class="type">int</span> <span class="operator">=</span> Field(description<span class="operator">=</span>&quot;Month&quot;)</span><br><span class="line">    <span class="keyword">day</span>: <span class="type">int</span> <span class="operator">=</span> Field(description<span class="operator">=</span>&quot;Day&quot;)</span><br><span class="line">    era: str <span class="operator">=</span> Field(description<span class="operator">=</span>&quot;BC or AD&quot;)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">from</span> langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers import PydanticOutputParser</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_name <span class="operator">=</span> <span class="string">&#x27;gpt-4o-mini&#x27;</span></span><br><span class="line">temperature <span class="operator">=</span> <span class="number">0</span></span><br><span class="line">llm <span class="operator">=</span> ChatOpenAI(model_name<span class="operator">=</span>model_name, temperature<span class="operator">=</span>temperature)</span><br><span class="line"></span><br><span class="line"># 定义结构化输出的模型</span><br><span class="line">structured_llm <span class="operator">=</span> llm.with_structured_output(<span class="type">Date</span>)</span><br><span class="line"></span><br><span class="line">template <span class="operator">=</span> &quot;&quot;&quot;提取用户输入中的日期。</span><br><span class="line">用户输入:</span><br><span class="line">&#123;query&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">prompt <span class="operator">=</span> PromptTemplate(</span><br><span class="line">    template<span class="operator">=</span>template,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">query <span class="operator">=</span> &quot;2023年四月6日天气晴...&quot;</span><br><span class="line">input_prompt <span class="operator">=</span> prompt.format_prompt(query<span class="operator">=</span>query)</span><br><span class="line"></span><br><span class="line">structured_llm.invoke(input_prompt)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Date(year&#x3D;2023, month&#x3D;4, day&#x3D;6, era&#x3D;’AD’)</p>
</blockquote>
<h4 id="2-3-2-输出指定格式的-JSON"><a href="#2-3-2-输出指定格式的-JSON" class="headerlink" title="2.3.2 输出指定格式的 JSON"></a>2.3.2 输出指定格式的 JSON</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">json_schema = &#123;</span><br><span class="line">    <span class="string">&quot;title&quot;</span>: <span class="string">&quot;Date&quot;</span>,</span><br><span class="line">    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;Formated date expression&quot;</span>,</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">    <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;year&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;integer&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;year, YYYY&quot;</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;month&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;integer&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;month, MM&quot;</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;day&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;integer&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;day, DD&quot;</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;era&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;BC or AD&quot;</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br><span class="line">structured_llm = llm.<span class="built_in">with_structured_output</span>(json_schema)</span><br><span class="line"></span><br><span class="line">structured_llm.<span class="built_in">invoke</span>(input_prompt)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>{‘year’: 2023, ‘month’: 4, ‘day’: 6}</p>
</blockquote>
<h4 id="2-3-3-使用-OutputParser"><a href="#2-3-3-使用-OutputParser" class="headerlink" title="2.3.3 使用 OutputParser"></a>2.3.3 使用 OutputParser</h4><p><code>OutputParser</code> 可以按指定格式解析模型的输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> JsonOutputParser</span><br><span class="line"></span><br><span class="line">parser = JsonOutputParser(pydantic_object=Date)</span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=<span class="string">&quot;提取用户输入中的日期。\n用户输入:&#123;query&#125;\n&#123;format_instructions&#125;&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;query&quot;</span>],</span><br><span class="line">    partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: parser.get_format_instructions()&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">input_prompt = prompt.format_prompt(query=query)</span><br><span class="line">output = llm.invoke(input_prompt)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;原始输出:\n&quot;</span>+output.content)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n解析后:&quot;</span>)</span><br><span class="line">parser.invoke(output)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>原始输出:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;year&quot;</span><span class="punctuation">:</span> <span class="number">2023</span><span class="punctuation">,</span> <span class="attr">&quot;month&quot;</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span> <span class="attr">&quot;day&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span> <span class="attr">&quot;era&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AD&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>



<p>解析后:</p>
<p>{‘year’: 2023, ‘month’: 4, ‘day’: 6, ‘era’: ‘AD’}</p>
</blockquote>
<p>也可以用 <code>PydanticOutputParser</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> PydanticOutputParser</span><br><span class="line"></span><br><span class="line">parser = PydanticOutputParser(pydantic_object=Date)</span><br><span class="line"></span><br><span class="line">input_prompt = prompt.format_prompt(query=query)</span><br><span class="line">output = llm.invoke(input_prompt)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;原始输出:\n&quot;</span>+output.content)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n解析后:&quot;</span>)</span><br><span class="line">parser.invoke(output)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>原始输出:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;year&quot;</span><span class="punctuation">:</span> <span class="number">2023</span><span class="punctuation">,</span> <span class="attr">&quot;month&quot;</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span> <span class="attr">&quot;day&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span> <span class="attr">&quot;era&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AD&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>



<p>解析后:</p>
<p>Date(year&#x3D;2023, month&#x3D;4, day&#x3D;6, era&#x3D;’AD’)</p>
</blockquote>
<p><code>OutputFixingParser</code> 利用大模型做格式自动纠错</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.output_parsers <span class="keyword">import</span> OutputFixingParser</span><br><span class="line"></span><br><span class="line">new_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI())</span><br><span class="line"></span><br><span class="line">bad_output = output.content.replace(<span class="string">&quot;4&quot;</span>,<span class="string">&quot;四&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;PydanticOutputParser:&quot;</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    parser.invoke(bad_output)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;OutputFixingParser:&quot;</span>)</span><br><span class="line">new_parser.invoke(bad_output)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>PydanticOutputParser:</p>
<p>Invalid json output: &#96;&#96;&#96;json</p>
<p>{“year”: 2023, “month”: 四, “day”: 6, “era”: “AD”}</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">OutputFixingParser:</span><br><span class="line">Date(year=2023, month=4, day=6, era=&#x27;AD&#x27;)</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="2-4-Function-Calling"><a href="#2-4-Function-Calling" class="headerlink" title="2.4 Function Calling"></a>2.4 Function Calling</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a: <span class="built_in">int</span>, b: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Add two integers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        a: First integer</span></span><br><span class="line"><span class="string">        b: Second integer</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multiply</span>(<span class="params">a: <span class="built_in">int</span>, b: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Multiply two integers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        a: First integer</span></span><br><span class="line"><span class="string">        b: Second integer</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> a * b</span><br><span class="line">    </span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools([add, multiply])</span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;3的4倍是多少?&quot;</span></span><br><span class="line">messages = [HumanMessage(query)]</span><br><span class="line"></span><br><span class="line">output = llm_with_tools.invoke(messages)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(json.dumps(output.tool_calls, indent=<span class="number">4</span>))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[</p>
<p>​    {</p>
<p>​        “name”: “multiply”,</p>
<p>​        “args”: {</p>
<p>​            “a”: 3,</p>
<p>​            “b”: 4</p>
<p>​        },</p>
<p>​        “id”: “call_0vHXqogx0m34oPJdoCkm36io”,</p>
<p>​        “type”: “tool_call”</p>
<p>​    }</p>
<p>]</p>
</blockquote>
<p>回传 Funtion Call 的结果</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">messages.<span class="built_in">append</span>(output)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> tool_call in output.tool_calls:</span><br><span class="line">    selected_tool = &#123;<span class="string">&quot;add&quot;</span>: add, <span class="string">&quot;multiply&quot;</span>: multiply&#125;[tool_call[<span class="string">&quot;name&quot;</span>].lower()]</span><br><span class="line">    tool_msg = selected_tool.invoke(tool_call)</span><br><span class="line">    messages.<span class="built_in">append</span>(tool_msg)</span><br><span class="line"></span><br><span class="line">new_output = llm_with_tools.invoke(messages)</span><br><span class="line"><span class="built_in">print</span>(messages)</span><br><span class="line"><span class="built_in">print</span>(new_output.content)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[HumanMessage(content&#x3D;’3的4倍是多少?’), AIMessage(content&#x3D;’’, additional_kwargs&#x3D;{‘tool_calls’: [{‘id’: ‘call_0vHXqogx0m34oPJdoCkm36io’, ‘function’: {‘arguments’: ‘{“a”:3,”b”:4}’, ‘name’: ‘multiply’}, ‘type’: ‘function’}], ‘refusal’: None}, response_metadata&#x3D;{‘token_usage’: {‘completion_tokens’: 17, ‘prompt_tokens’: 97, ‘total_tokens’: 114}, ‘model_name’: ‘gpt-4o-mini-2024-07-18’, ‘system_fingerprint’: ‘fp_48196bc67a’, ‘finish_reason’: ‘tool_calls’, ‘logprobs’: None}, id&#x3D;’run-c1d06b98-1412-4456-9ff2-73953ca4086e-0’, tool_calls&#x3D;[{‘name’: ‘multiply’, ‘args’: {‘a’: 3, ‘b’: 4}, ‘id’: ‘call_0vHXqogx0m34oPJdoCkm36io’, ‘type’: ‘tool_call’}], usage_metadata&#x3D;{‘input_tokens’: 97, ‘output_tokens’: 17, ‘total_tokens’: 114}), ToolMessage(content&#x3D;’12’, name&#x3D;’multiply’, tool_call_id&#x3D;’call_0vHXqogx0m34oPJdoCkm36io’), AIMessage(content&#x3D;’’, additional_kwargs&#x3D;{‘tool_calls’: [{‘id’: ‘call_0vHXqogx0m34oPJdoCkm36io’, ‘function’: {‘arguments’: ‘{“a”:3,”b”:4}’, ‘name’: ‘multiply’}, ‘type’: ‘function’}], ‘refusal’: None}, response_metadata&#x3D;{‘token_usage’: {‘completion_tokens’: 17, ‘prompt_tokens’: 97, ‘total_tokens’: 114}, ‘model_name’: ‘gpt-4o-mini-2024-07-18’, ‘system_fingerprint’: ‘fp_48196bc67a’, ‘finish_reason’: ‘tool_calls’, ‘logprobs’: None}, id&#x3D;’run-c1d06b98-1412-4456-9ff2-73953ca4086e-0’, tool_calls&#x3D;[{‘name’: ‘multiply’, ‘args’: {‘a’: 3, ‘b’: 4}, ‘id’: ‘call_0vHXqogx0m34oPJdoCkm36io’, ‘type’: ‘tool_call’}], usage_metadata&#x3D;{‘input_tokens’: 97, ‘output_tokens’: 17, ‘total_tokens’: 114}), ToolMessage(content&#x3D;’12’, name&#x3D;’multiply’, tool_call_id&#x3D;’call_0vHXqogx0m34oPJdoCkm36io’)]</p>
<p>3的4倍是12。</p>
</blockquote>
<h3 id="2-5-小结"><a href="#2-5-小结" class="headerlink" title="2.5 小结"></a>2.5 小结</h3><ol>
<li>LangChain 统一封装了各种模型的调用接口，包括补全型和对话型两种</li>
<li>LangChain 提供了 PromptTemplate 类，可以自定义带变量的模板</li>
<li>LangChain 提供了一些列输出解析器，用于将大模型的输出解析成结构化对象</li>
<li>LangChain 提供了 Function Calling 的封装</li>
<li>上述模型属于 LangChain 中较为实用的部分</li>
</ol>
<h2 id="3-数据连接封装"><a href="#3-数据连接封装" class="headerlink" title="3 数据连接封装"></a>3 数据连接封装</h2><img src="/2025/03/26/07-LangChain/1742985220519-2.jpeg" class="">

<h3 id="3-1-文档加载器：Document-Loaders"><a href="#3-1-文档加载器：Document-Loaders" class="headerlink" title="3.1 文档加载器：Document Loaders"></a>3.1 文档加载器：Document Loaders</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#!pip install pymupdf</span><br><span class="line"></span><br><span class="line">from langchain_community.document_loaders <span class="keyword">import</span> PyMuPDFLoader</span><br><span class="line"></span><br><span class="line">loader = PyMuPDFLoader(<span class="string">&quot;llama2.pdf&quot;</span>)</span><br><span class="line">pages = loader.load_and_split()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pages[<span class="number">0</span>].page_content)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Llama 2: Open Foundation and Fine-Tuned Chat Models</p>
<p>Hugo Touvron∗</p>
<p>Louis Martin†</p>
<p>Kevin Stone†</p>
<p>Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra</p>
<p>Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen</p>
<p>Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller</p>
<p>Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou</p>
<p>Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev</p>
<p>Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich</p>
<p>Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra</p>
<p>Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi</p>
<p>Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang</p>
<p>Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang</p>
<p>Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic</p>
<p>Sergey Edunov</p>
<p>Thomas Scialom∗</p>
<p>GenAI, Meta</p>
<p>Abstract</p>
<p>In this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned</p>
<p>large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.</p>
<p>Our ﬁne-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our</p>
<p>models outperform open-source chat models on most benchmarks we tested, and based on</p>
<p>our human evaluations for helpfulness and safety, may be a suitable substitute for closed-</p>
<p>source models. We provide a detailed description of our approach to ﬁne-tuning and safety</p>
<p>improvements of Llama 2-Chat in order to enable the community to build on our work and</p>
<p>contribute to the responsible development of LLMs.</p>
<p>∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com</p>
<p>†Second author</p>
<p>Contributions for all the authors can be found in Section A.1.</p>
<p>arXiv:2307.09288v2  [cs.CL]  19 Jul 2023</p>
</blockquote>
<h3 id="3-2-文档处理器"><a href="#3-2-文档处理器" class="headerlink" title="3.2 文档处理器"></a>3.2 文档处理器</h3><h3 id="3-2-1-TextSplitter"><a href="#3-2-1-TextSplitter" class="headerlink" title="3.2.1 TextSplitter"></a>3.2.1 TextSplitter</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#!pip install --upgrade langchain-text-splitters</span><br><span class="line"></span><br><span class="line">from langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">200</span>,</span><br><span class="line">    chunk_overlap=<span class="number">100</span>, </span><br><span class="line">    length_function=<span class="built_in">len</span>,</span><br><span class="line">    add_start_index=True,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">paragraphs = text_splitter.create_documents([pages[<span class="number">0</span>].page_content])</span><br><span class="line"><span class="keyword">for</span> para in paragraphs:</span><br><span class="line">    <span class="built_in">print</span>(para.page_content)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------&#x27;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Llama 2: Open Foundation and Fine-Tuned Chat Models</p>
<p>Hugo Touvron∗</p>
<p>Louis Martin†</p>
<p>Kevin Stone†</p>
<p>Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra</p>
<hr>
<p>Kevin Stone†</p>
<p>Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra</p>
<p>Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen</p>
<hr>
<p>Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen</p>
<p>Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller</p>
<hr>
<p>Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller</p>
<p>Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou</p>
<hr>
<p>Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou</p>
<p>Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev</p>
<hr>
<p>Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev</p>
<p>Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich</p>
<hr>
<p>Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich</p>
<p>Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra</p>
<hr>
<p>Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra</p>
<p>Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi</p>
<hr>
<p>Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi</p>
<p>Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang</p>
<hr>
<p>Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang</p>
<p>Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang</p>
<hr>
<p>Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang</p>
<p>Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic</p>
<p>Sergey Edunov</p>
<p>Thomas Scialom∗</p>
<hr>
<p>Sergey Edunov</p>
<p>Thomas Scialom∗</p>
<p>GenAI, Meta</p>
<p>Abstract</p>
<p>In this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned</p>
<hr>
<p>Abstract</p>
<p>In this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned</p>
<p>large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.</p>
<hr>
<p>large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.</p>
<p>Our ﬁne-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our</p>
<hr>
<p>Our ﬁne-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our</p>
<p>models outperform open-source chat models on most benchmarks we tested, and based on</p>
<hr>
<p>models outperform open-source chat models on most benchmarks we tested, and based on</p>
<p>our human evaluations for helpfulness and safety, may be a suitable substitute for closed-</p>
<hr>
<p>our human evaluations for helpfulness and safety, may be a suitable substitute for closed-</p>
<p>source models. We provide a detailed description of our approach to ﬁne-tuning and safety</p>
<hr>
<p>source models. We provide a detailed description of our approach to ﬁne-tuning and safety</p>
<p>improvements of Llama 2-Chat in order to enable the community to build on our work and</p>
<hr>
<p>improvements of Llama 2-Chat in order to enable the community to build on our work and</p>
<p>contribute to the responsible development of LLMs.</p>
<hr>
<p>contribute to the responsible development of LLMs.</p>
<p>∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com</p>
<p>†Second author</p>
<hr>
<p>∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com</p>
<p>†Second author</p>
<p>Contributions for all the authors can be found in Section A.1.</p>
<p>arXiv:2307.09288v2  [cs.CL]  19 Jul 2023</p>
<hr>
</blockquote>
<p>类似 LlamaIndex，LangChain 也提供了丰富的 <code>Document Loaders</code> 和 <code>Text Splitters</code>。</p>
<h3 id="3-3-向量数据库与向量检索"><a href="#3-3-向量数据库与向量检索" class="headerlink" title="3.3 向量数据库与向量检索"></a>3.3 向量数据库与向量检索</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> PyMuPDFLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载文档</span></span><br><span class="line">loader = PyMuPDFLoader(<span class="string">&quot;llama2.pdf&quot;</span>)</span><br><span class="line">pages = loader.load_and_split()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文档切分</span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">300</span>,</span><br><span class="line">    chunk_overlap=<span class="number">100</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span>,</span><br><span class="line">    add_start_index=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">texts = text_splitter.create_documents(</span><br><span class="line">    [page.page_content <span class="keyword">for</span> page <span class="keyword">in</span> pages[:<span class="number">4</span>]]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 灌库</span></span><br><span class="line">embeddings = OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-ada-002&quot;</span>)</span><br><span class="line">db = FAISS.from_documents(texts, embeddings)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检索 top-3 结果</span></span><br><span class="line">retriever = db.as_retriever(search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">3</span>&#125;)</span><br><span class="line"></span><br><span class="line">docs = retriever.invoke(<span class="string">&quot;llama2有多少参数&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:</span><br><span class="line">    <span class="built_in">print</span>(doc.page_content)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;----&quot;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>but are not releasing.§</p>
<ol>
<li>Llama 2-Chat, a ﬁne-tuned version of Llama 2 that is optimized for dialogue use cases. We release</li>
</ol>
<p>variants of this model with 7B, 13B, and 70B parameters as well.</p>
<p>We believe that the open release of LLMs, when done safely, will be a net beneﬁt to society. Like all LLMs,</p>
<hr>
<p>Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,</p>
<p>Llama 2-Chat models generally perform better than existing open-source models. They also appear to</p>
<hr>
<p>large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.</p>
<p>Our ﬁne-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our</p>
<p>models outperform open-source chat models on most benchmarks we tested, and based on</p>
<hr>
</blockquote>
<p>更多的三方检索组件链接，参考：<a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/">https://python.langchain.com/v0.2/docs/integrations/vectorstores/</a></p>
<h3 id="3-4-小结"><a href="#3-4-小结" class="headerlink" title="3.4 小结"></a>3.4 小结</h3><ol>
<li>文档处理部分，建议在实际应用中详细测试后使用</li>
<li>与向量数据库的链接部分本质是接口封装，向量数据库需要自己选型</li>
</ol>
<h2 id="4-对话历史管理"><a href="#4-对话历史管理" class="headerlink" title="4 对话历史管理"></a>4 对话历史管理</h2><h3 id="4-1-历史记录的剪裁"><a href="#4-1-历史记录的剪裁" class="headerlink" title="4.1 历史记录的剪裁"></a>4.1 历史记录的剪裁</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.messages import (</span><br><span class="line">    AIMessage,</span><br><span class="line">    HumanMessage,</span><br><span class="line">    SystemMessage,</span><br><span class="line">    trim_messages,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line">messages <span class="operator">=</span> [</span><br><span class="line">    SystemMessage(&quot;you&#x27;re a good assistant, you always respond with a joke.&quot;),</span><br><span class="line">    HumanMessage(&quot;i wonder why it&#x27;s called langchain&quot;),</span><br><span class="line">    AIMessage(</span><br><span class="line">        <span class="string">&#x27;Well, I guess they thought &quot;WordRope&quot; and &quot;SentenceString&quot; just didn\&#x27;</span>t have the same ring <span class="keyword">to</span> it<span class="operator">!</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">    ),</span></span><br><span class="line"><span class="string">    HumanMessage(&quot;and who is harrison chasing anyways&quot;),</span></span><br><span class="line"><span class="string">    AIMessage(</span></span><br><span class="line"><span class="string">        &quot;Hmmm let me think.\n\nWhy, he&#x27;</span>s probably chasing after the <span class="keyword">last</span> cup <span class="keyword">of</span> coffee <span class="keyword">in</span> the office<span class="operator">!</span>&quot;</span><br><span class="line">    ),</span><br><span class="line">    HumanMessage(&quot;what do you <span class="keyword">call</span> a speechless parrot&quot;),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">trim_messages(</span><br><span class="line">    messages,</span><br><span class="line">    max_tokens=45,</span><br><span class="line">    strategy=&quot;<span class="keyword">last</span>&quot;,</span><br><span class="line">    token_counter=ChatOpenAI(model=&quot;gpt<span class="number">-4</span>o<span class="operator">-</span>mini&quot;),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[AIMessage(content&#x3D;”Hmmm let me think.\n\nWhy, he’s probably chasing after the last cup of coffee in the office!”),</p>
<p> HumanMessage(content&#x3D;’what do you call a speechless parrot’)]</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 保留 <span class="keyword">system</span> prompt</span><br><span class="line">trim_messages(</span><br><span class="line">    messages,</span><br><span class="line">    max_tokens<span class="operator">=</span><span class="number">45</span>,</span><br><span class="line">    strategy<span class="operator">=</span>&quot;last&quot;,</span><br><span class="line">    token_counter<span class="operator">=</span>ChatOpenAI(model<span class="operator">=</span>&quot;gpt-4o-mini&quot;),</span><br><span class="line">    include_system<span class="operator">=</span><span class="literal">True</span>,</span><br><span class="line">    allow_partial<span class="operator">=</span><span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[SystemMessage(content&#x3D;”you’re a good assistant, you always respond with a joke.”),</p>
<p> HumanMessage(content&#x3D;’what do you call a speechless parrot’)]</p>
</blockquote>
<h3 id="4-2-过滤带标识的历史记录"><a href="#4-2-过滤带标识的历史记录" class="headerlink" title="4.2 过滤带标识的历史记录"></a>4.2 过滤带标识的历史记录</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> (</span><br><span class="line">    AIMessage,</span><br><span class="line">    HumanMessage,</span><br><span class="line">    SystemMessage,</span><br><span class="line">    filter_messages,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(<span class="string">&quot;you are a good assistant&quot;</span>, <span class="built_in">id</span>=<span class="string">&quot;1&quot;</span>),</span><br><span class="line">    HumanMessage(<span class="string">&quot;example input&quot;</span>, <span class="built_in">id</span>=<span class="string">&quot;2&quot;</span>, name=<span class="string">&quot;example_user&quot;</span>),</span><br><span class="line">    AIMessage(<span class="string">&quot;example output&quot;</span>, <span class="built_in">id</span>=<span class="string">&quot;3&quot;</span>, name=<span class="string">&quot;example_assistant&quot;</span>),</span><br><span class="line">    HumanMessage(<span class="string">&quot;real input&quot;</span>, <span class="built_in">id</span>=<span class="string">&quot;4&quot;</span>, name=<span class="string">&quot;bob&quot;</span>),</span><br><span class="line">    AIMessage(<span class="string">&quot;real output&quot;</span>, <span class="built_in">id</span>=<span class="string">&quot;5&quot;</span>, name=<span class="string">&quot;alice&quot;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">filter_messages(messages, include_types=<span class="string">&quot;human&quot;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[HumanMessage(content&#x3D;’example input’, name&#x3D;’example_user’, id&#x3D;’2’),</p>
<p> HumanMessage(content&#x3D;’real input’, name&#x3D;’bob’, id&#x3D;’4’)]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filter_messages(messages, exclude_names=[<span class="string">&quot;example_user&quot;</span>, <span class="string">&quot;example_assistant&quot;</span>])</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[SystemMessage(content&#x3D;’you are a good assistant’, id&#x3D;’1’),</p>
<p> HumanMessage(content&#x3D;’real input’, name&#x3D;’bob’, id&#x3D;’4’),</p>
<p> AIMessage(content&#x3D;’real output’, name&#x3D;’alice’, id&#x3D;’5’)]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filter_messages(messages, include_types=[HumanMessage, AIMessage], exclude_ids=[<span class="string">&quot;3&quot;</span>])</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[HumanMessage(content&#x3D;’example input’, name&#x3D;’example_user’, id&#x3D;’2’),</p>
<p> HumanMessage(content&#x3D;’real input’, name&#x3D;’bob’, id&#x3D;’4’),</p>
<p> AIMessage(content&#x3D;’real output’, name&#x3D;’alice’, id&#x3D;’5’)]</p>
</blockquote>
<p><strong>思考：</strong>你能想出这个功能的一个使用场景吗？</p>
<h2 id="5-Chain-和-LangChain-Expression-Language-LCEL"><a href="#5-Chain-和-LangChain-Expression-Language-LCEL" class="headerlink" title="5 Chain 和 LangChain Expression Language (LCEL)"></a>5 Chain 和 LangChain Expression Language (LCEL)</h2><p>LangChain Expression Language（LCEL）是一种声明式语言，可轻松组合不同的调用顺序构成 Chain。LCEL 自创立之初就被设计为能够支持将原型投入生产环境，<strong>无需代码更改</strong>，从最简单的“提示+LLM”链到最复杂的链（已有用户成功在生产环境中运行包含数百个步骤的 LCEL Chain）。</p>
<p>LCEL 的一些亮点包括：</p>
<ol>
<li><strong>流支持</strong>：使用 LCEL 构建 Chain 时，你可以获得最佳的首个令牌时间（即从输出开始到首批输出生成的时间）。对于某些 Chain，这意味着可以直接从 LLM 流式传输令牌到流输出解析器，从而以与 LLM 提供商输出原始令牌相同的速率获得解析后的、增量的输出。</li>
<li><strong>异步支持</strong>：任何使用 LCEL 构建的链条都可以通过同步 API（例如，在 Jupyter 笔记本中进行原型设计时）和异步 API（例如，在 LangServe 服务器中）调用。这使得相同的代码可用于原型设计和生产环境，具有出色的性能，并能够在同一服务器中处理多个并发请求。</li>
<li><strong>优化的<strong><strong>并行</strong></strong>执行</strong>：当你的 LCEL 链条有可以并行执行的步骤时（例如，从多个检索器中获取文档），我们会自动执行，无论是在同步还是异步接口中，以实现最小的延迟。</li>
<li><strong>重试和回退</strong>：为 LCEL 链的任何部分配置重试和回退。这是使链在规模上更可靠的绝佳方式。目前我们正在添加重试&#x2F;回退的流媒体支持，因此你可以在不增加任何延迟成本的情况下获得增加的可靠性。</li>
<li><strong>访问中间结果</strong>：对于更复杂的链条，访问在最终输出产生之前的中间步骤的结果通常非常有用。这可以用于让最终用户知道正在发生一些事情，甚至仅用于调试链条。你可以流式传输中间结果，并且在每个 LangServe 服务器上都可用。</li>
<li><strong>输入和输出模式</strong>：输入和输出模式为每个 LCEL 链提供了从链的结构推断出的 Pydantic 和 JSONSchema 模式。这可以用于输入和输出的验证，是 LangServe 的一个组成部分。</li>
<li><strong>无缝 LangSmith 跟踪集成</strong>：随着链条变得越来越复杂，理解每一步发生了什么变得越来越重要。通过 LCEL，所有步骤都自动记录到 LangSmith，以实现最大的可观察性和可调试性。</li>
<li><strong>无缝 LangServe 部署集成</strong>：任何使用 LCEL 创建的链都可以轻松地使用 LangServe 进行部署。</li>
</ol>
<p>原文：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/expression_language/">https://python.langchain.com/docs/expression_language/</a></p>
<h3 id="5-1-Pipeline-式调用-PromptTemplate-LLM-和-OutputParser"><a href="#5-1-Pipeline-式调用-PromptTemplate-LLM-和-OutputParser" class="headerlink" title="5.1 Pipeline 式调用 PromptTemplate, LLM 和 OutputParser"></a>5.1 Pipeline 式调用 PromptTemplate, LLM 和 OutputParser</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables <span class="keyword">import</span> RunnablePassthrough</span><br><span class="line"><span class="keyword">from</span> langchain_core.pydantic_v1 <span class="keyword">import</span> BaseModel, Field, validator</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Optional</span></span><br><span class="line"><span class="keyword">from</span> enum <span class="keyword">import</span> Enum</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SortEnum</span>(<span class="built_in">str</span>, Enum):</span><br><span class="line">    data = <span class="string">&#x27;data&#x27;</span></span><br><span class="line">    price = <span class="string">&#x27;price&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OrderingEnum</span>(<span class="built_in">str</span>, Enum):</span><br><span class="line">    ascend = <span class="string">&#x27;ascend&#x27;</span></span><br><span class="line">    descend = <span class="string">&#x27;descend&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Semantics</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name: <span class="type">Optional</span>[<span class="built_in">str</span>] = Field(description=<span class="string">&quot;流量包名称&quot;</span>, default=<span class="literal">None</span>)</span><br><span class="line">    price_lower: <span class="type">Optional</span>[<span class="built_in">int</span>] = Field(description=<span class="string">&quot;价格下限&quot;</span>, default=<span class="literal">None</span>)</span><br><span class="line">    price_upper: <span class="type">Optional</span>[<span class="built_in">int</span>] = Field(description=<span class="string">&quot;价格上限&quot;</span>, default=<span class="literal">None</span>)</span><br><span class="line">    data_lower: <span class="type">Optional</span>[<span class="built_in">int</span>] = Field(description=<span class="string">&quot;流量下限&quot;</span>, default=<span class="literal">None</span>)</span><br><span class="line">    data_upper: <span class="type">Optional</span>[<span class="built_in">int</span>] = Field(description=<span class="string">&quot;流量上限&quot;</span>, default=<span class="literal">None</span>)</span><br><span class="line">    sort_by: <span class="type">Optional</span>[SortEnum] = Field(description=<span class="string">&quot;按价格或流量排序&quot;</span>, default=<span class="literal">None</span>)</span><br><span class="line">    ordering: <span class="type">Optional</span>[OrderingEnum] = Field(</span><br><span class="line">        description=<span class="string">&quot;升序或降序排列&quot;</span>, default=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Prompt 模板</span></span><br><span class="line">prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;将用户的输入解析成JSON表示。&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;text&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型</span></span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;gpt-4o&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">structured_llm = llm.with_structured_output(Semantics)</span><br><span class="line"></span><br><span class="line"><span class="comment"># LCEL 表达式</span></span><br><span class="line">runnable = (</span><br><span class="line">    &#123;<span class="string">&quot;text&quot;</span>: RunnablePassthrough()&#125; | prompt | structured_llm</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接运行</span></span><br><span class="line">ret = runnable.invoke(<span class="string">&quot;不超过100元的流量大的套餐有哪些&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    json.dumps(</span><br><span class="line">        ret.<span class="built_in">dict</span>(),</span><br><span class="line">        indent = <span class="number">4</span>,</span><br><span class="line">        ensure_ascii=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>{</p>
<p>​    “name”: null,</p>
<p>​    “price_lower”: null,</p>
<p>​    “price_upper”: 100,</p>
<p>​    “data_lower”: null,</p>
<p>​    “data_upper”: null,</p>
<p>​    “sort_by”: “data”,</p>
<p>​    “ordering”: “descend”</p>
<p>}</p>
</blockquote>
<h4 id="流式输出"><a href="#流式输出" class="headerlink" title="流式输出"></a>流式输出</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">runnable = (</span><br><span class="line">    &#123;<span class="string">&quot;text&quot;</span>: RunnablePassthrough()&#125; | prompt | llm | StrOutputParser()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 流式输出</span></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> runnable.stream(<span class="string">&quot;不超过100元的流量大的套餐有哪些&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(s, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;budget&quot;</span><span class="punctuation">:</span> <span class="number">100</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;criteria&quot;</span><span class="punctuation">:</span> <span class="string">&quot;large data package&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>注意:</strong> 在当前的文档中 LCEL 产生的对象，被叫做 runnable 或 chain，经常两种叫法混用。本质就是一个自定义调用流程。</p>
<p><strong>使用 LCEL 的价值，也就是 LangChain 的核心价值。</strong> 官方从不同角度给出了举例说明：<a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/expression_language/why/">https://python.langchain.com/v0.1/docs/expression_language/why/</a></p>
<h3 id="5-2-用-LCEL-实现-RAG"><a href="#5-2-用-LCEL-实现-RAG" class="headerlink" title="5.2 用 LCEL 实现 RAG"></a>5.2 用 LCEL 实现 RAG</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> PyMuPDFLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载文档</span></span><br><span class="line">loader = PyMuPDFLoader(<span class="string">&quot;llama2.pdf&quot;</span>)</span><br><span class="line">pages = loader.load_and_split()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文档切分</span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">300</span>,</span><br><span class="line">    chunk_overlap=<span class="number">100</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span>,</span><br><span class="line">    add_start_index=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">texts = text_splitter.create_documents(</span><br><span class="line">    [page.page_content <span class="keyword">for</span> page <span class="keyword">in</span> pages[:<span class="number">4</span>]]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 灌库</span></span><br><span class="line">embeddings = OpenAIEmbeddings(model=<span class="string">&quot;text-embedding-ada-002&quot;</span>)</span><br><span class="line">db = FAISS.from_documents(texts, embeddings)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检索 top-2 结果</span></span><br><span class="line">retriever = db.as_retriever(search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">2</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.schema.output_parser <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain.schema.runnable <span class="keyword">import</span> RunnablePassthrough</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prompt模板</span></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;Answer the question based only on the following context:</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: &#123;question&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">prompt = ChatPromptTemplate.from_template(template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Chain</span></span><br><span class="line">rag_chain = (</span><br><span class="line">    &#123;<span class="string">&quot;question&quot;</span>: RunnablePassthrough(), <span class="string">&quot;context&quot;</span>: retriever&#125;</span><br><span class="line">    | prompt</span><br><span class="line">    | llm</span><br><span class="line">    | StrOutputParser()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">rag_chain.invoke(<span class="string">&quot;Llama 2有多少参数&quot;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>‘Llama 2有7B、13B和70B参数的变体。’</p>
</blockquote>
<h3 id="5-3-用-LCEL-实现工厂模式（选）"><a href="#5-3-用-LCEL-实现工厂模式（选）" class="headerlink" title="5.3 用 LCEL 实现工厂模式（选）"></a>5.3 用 LCEL 实现工厂模式（选）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.runnables.utils <span class="keyword">import</span> ConfigurableField</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models <span class="keyword">import</span> QianfanChatEndpoint</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> HumanMessage</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型1</span></span><br><span class="line">ernie_model = QianfanChatEndpoint(</span><br><span class="line">    qianfan_ak=os.getenv(<span class="string">&#x27;ERNIE_CLIENT_ID&#x27;</span>),</span><br><span class="line">    qianfan_sk=os.getenv(<span class="string">&#x27;ERNIE_CLIENT_SECRET&#x27;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型2</span></span><br><span class="line">gpt_model = ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 configurable_alternatives 按指定字段选择模型</span></span><br><span class="line">model = gpt_model.configurable_alternatives(</span><br><span class="line">    ConfigurableField(<span class="built_in">id</span>=<span class="string">&quot;llm&quot;</span>), </span><br><span class="line">    default_key=<span class="string">&quot;gpt&quot;</span>, </span><br><span class="line">    ernie=ernie_model,</span><br><span class="line">    <span class="comment"># claude=claude_model,</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prompt 模板</span></span><br><span class="line">prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        HumanMessagePromptTemplate.from_template(<span class="string">&quot;&#123;query&#125;&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># LCEL</span></span><br><span class="line">chain = (</span><br><span class="line">    &#123;<span class="string">&quot;query&quot;</span>: RunnablePassthrough()&#125; </span><br><span class="line">    | prompt</span><br><span class="line">    | model </span><br><span class="line">    | StrOutputParser()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行时指定模型 &quot;gpt&quot; or &quot;ernie&quot;</span></span><br><span class="line">ret = chain.with_config(configurable=&#123;<span class="string">&quot;llm&quot;</span>: <span class="string">&quot;ernie&quot;</span>&#125;).invoke(<span class="string">&quot;请自我介绍&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ret)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>您好，我是文心一言，英文名是ERNIE Bot。我能够与人对话互动，回答问题，协助创作，高效便捷地帮助人们获取信息、知识和灵感。</p>
</blockquote>
<p>扩展阅读：什么是**<a target="_blank" rel="noopener" href="https://www.runoob.com/design-pattern/factory-pattern.html">工厂模式</a><strong>；</strong><a target="_blank" rel="noopener" href="https://www.runoob.com/design-pattern/design-pattern-intro.html">设计模式</a>**概览。</p>
<p><strong>思考：</strong>从模块间解依赖角度，LCEL的意义是什么？</p>
<h3 id="54-存储与管理对话历史"><a href="#54-存储与管理对话历史" class="headerlink" title="54 存储与管理对话历史"></a>54 存储与管理对话历史</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.chat_message_histories <span class="keyword">import</span> SQLChatMessageHistory</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_session_history</span>(<span class="params">session_id</span>):</span><br><span class="line">    <span class="comment"># 通过 session_id 区分对话历史，并存储在 sqlite 数据库中</span></span><br><span class="line">    <span class="keyword">return</span> SQLChatMessageHistory(session_id, <span class="string">&quot;sqlite:///memory.db&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables.history <span class="keyword">import</span> RunnableWithMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.schema.output_parser <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line">model = ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">runnable = model | StrOutputParser()</span><br><span class="line"></span><br><span class="line">runnable_with_history = RunnableWithMessageHistory(</span><br><span class="line">    runnable, <span class="comment"># 指定 runnable</span></span><br><span class="line">    get_session_history, <span class="comment"># 指定自定义的历史管理方法</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">runnable_with_history.invoke(</span><br><span class="line">    [HumanMessage(content=<span class="string">&quot;你好，我叫王&quot;</span>)],</span><br><span class="line">    config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: <span class="string">&quot;wzr&quot;</span>&#125;&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>‘你好，王！很高兴认识你。有什么我可以帮助你的吗？’</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">runnable_with_history.invoke(</span><br><span class="line">    [HumanMessage(content=<span class="string">&quot;你知道我叫什么名字&quot;</span>)],</span><br><span class="line">    config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: <span class="string">&quot;wzr&quot;</span>&#125;&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>‘是的，你刚刚告诉我你叫王。有什么我可以帮助你的吗？’</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">runnable_with_history.invoke(</span><br><span class="line">    [HumanMessage(content=<span class="string">&quot;你知道我叫什么名字&quot;</span>)],</span><br><span class="line">    config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: <span class="string">&quot;test&quot;</span>&#125;&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>‘抱歉，我无法知道你的名字。你可以告诉我你的名字，或者问我其他问题！’</p>
</blockquote>
<h3 id="通过-LCEL，还可以实现"><a href="#通过-LCEL，还可以实现" class="headerlink" title="通过 LCEL，还可以实现"></a>通过 LCEL，还可以实现</h3><ol>
<li>配置运行时变量：<a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/configure/">https://python.langchain.com/v0.2/docs/how_to/configure/</a></li>
<li>故障回退：<a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/fallbacks">https://python.langchain.com/v0.2/docs/how_to/fallbacks</a></li>
<li>并行调用：<a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/parallel/">https://python.langchain.com/v0.2/docs/how_to/parallel/</a></li>
<li>逻辑分支：<a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/routing/">https://python.langchain.com/v0.2/docs/how_to/routing/</a></li>
<li>动态创建 Chain: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/dynamic_chain/">https://python.langchain.com/v0.2/docs/how_to/dynamic_chain/</a></li>
</ol>
<p>更多例子：<a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/lcel_cheatsheet/">https://python.langchain.com/v0.2/docs/how_to/lcel_cheatsheet/</a></p>
<h2 id="6-智能体架构：Agent"><a href="#6-智能体架构：Agent" class="headerlink" title="6 智能体架构：Agent"></a>6 智能体架构：Agent</h2><h3 id="6-1-什么是智能体（Agent）"><a href="#6-1-什么是智能体（Agent）" class="headerlink" title="6.1 什么是智能体（Agent）"></a>6.1 什么是智能体（Agent）</h3><p>将大语言模型作为一个推理引擎。给定一个任务，智能体自动生成完成任务所需的步骤，执行相应动作（例如选择并调用工具），直到任务完成。</p>
<img src="/2025/03/26/07-LangChain/1742985220519-3.png" class="">

<h3 id="6-2-先定义一些工具：Tools"><a href="#6-2-先定义一些工具：Tools" class="headerlink" title="6.2 先定义一些工具：Tools"></a>6.2 先定义一些工具：Tools</h3><ul>
<li>可以是一个函数或三方 API</li>
<li>也可以把一个 Chain 或者 Agent 的 run()作为一个 Tool</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.utilities <span class="keyword">import</span> SerpAPIWrapper</span><br><span class="line"><span class="keyword">from</span> langchain.tools <span class="keyword">import</span> Tool, tool</span><br><span class="line"></span><br><span class="line">search = SerpAPIWrapper()</span><br><span class="line">tools = [</span><br><span class="line">    Tool.from_function(</span><br><span class="line">        func=search.run,</span><br><span class="line">        name=<span class="string">&quot;Search&quot;</span>,</span><br><span class="line">        description=<span class="string">&quot;useful for when you need to answer questions about current events&quot;</span></span><br><span class="line">    ),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>需要注册 <a target="_blank" rel="noopener" href="https://serpapi.com/">SerpAPI</a>（限量免费），并将 <code>SERPAPI_API_KEY</code> 写在环境变量中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> calendar</span><br><span class="line"><span class="keyword">import</span> dateutil.parser <span class="keyword">as</span> parser</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> date</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义工具</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool(<span class="params"><span class="string">&quot;weekday&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">weekday</span>(<span class="params">date_str: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert date to weekday name&quot;&quot;&quot;</span></span><br><span class="line">    d = parser.parse(date_str)</span><br><span class="line">    <span class="keyword">return</span> calendar.day_name[d.weekday()]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tools += [weekday]</span><br></pre></td></tr></table></figure>

<h3 id="6-3-智能体类型：ReAct"><a href="#6-3-智能体类型：ReAct" class="headerlink" title="6.3 智能体类型：ReAct"></a>6.3 智能体类型：ReAct</h3><img src="/2025/03/26/07-LangChain/1742985220520-4.png" class="">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !pip install google-search-results</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># !pip install --upgrade langchainhub</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> hub</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载一个现有的 Prompt 模板</span></span><br><span class="line">react_prompt = hub.pull(<span class="string">&quot;hwchase17/react&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(react_prompt.template)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Answer the following questions as best you can. You have access to the following tools:</p>
<p>{tools}</p>
<p>Use the following format:</p>
<p>Question: the input question you must answer</p>
<p>Thought: you should always think about what to do</p>
<p>Action: the action to take, should be one of [{tool_names}]</p>
<p>Action Input: the input to the action</p>
<p>Observation: the result of the action</p>
<p>… (this Thought&#x2F;Action&#x2F;Action Input&#x2F;Observation can repeat N times)</p>
<p>Thought: I now know the final answer</p>
<p>Final Answer: the final answer to the original input question</p>
<p>Begin!</p>
<p>Question: {input}</p>
<p>Thought:{agent_scratchpad}</p>
<p>&#x2F;opt&#x2F;conda&#x2F;lib&#x2F;python3.11&#x2F;site-packages&#x2F;langchain_core&#x2F;_api&#x2F;beta_decorator.py:87: LangChainBetaWarning: The function <code>loads</code> is in beta. It is actively being worked on, so the API may change.</p>
<p>  warn_beta(</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> AgentExecutor, create_react_agent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(model_name=<span class="string">&#x27;gpt-4o&#x27;</span>, temperature=<span class="number">0</span>, seed=<span class="number">23</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个 agent: 需要大模型、工具集、和 Prompt 模板</span></span><br><span class="line">agent = create_react_agent(llm, tools, react_prompt)</span><br><span class="line"><span class="comment"># 定义一个执行器：需要 agent 对象 和 工具集</span></span><br><span class="line">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行</span></span><br><span class="line">agent_executor.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;2024年周杰伦的演唱会星期几&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>&gt; Entering new AgentExecutor chain…周杰伦的演唱会日期没有在问题中提供，因此我需要先找到2024年周杰伦演唱会的具体日期，然后再确定那天是星期几。</strong> <strong>Action: Search</strong> <strong>Action Input: 2024年周杰伦演唱会日期</strong> <strong>华语乐坛天王周杰伦即唱响新加坡，为数以万计的歌迷们带来一场难忘的音乐盛宴！ 《嘉年华2024》世界巡回演唱会将于2024 年10 月11、12 和13 日（共三场）在新加坡国家体育场（National Stadium）上演，预售门票将于5 月29 日上午10 点正式开启！周杰伦的演唱会在2024年有三场，分别是10月11日、12日和13日。接下来，我需要确定这些日期分别是星期几。</strong> <strong>Action: weekday</strong> <strong>Action</strong> <strong>Input</strong><strong>: 2024-10-11FridayAction: weekday</strong> <strong>Action Input: 2024-10-12SaturdayAction: weekday</strong> <strong>Action Input: 2024-10-13SundayI now know the final answer.</strong> <strong>Final Answer: 2024年周杰伦的演唱会分别在星期五（10月11日）、星期六（10月12日）和星期日（10月13日）。&gt; Finished chain.</strong></p>
<p>{‘input’: ‘2024年周杰伦的演唱会星期几’,</p>
<p> ‘output’: ‘2024年周杰伦的演唱会分别在星期五（10月11日）、星期六（10月12日）和星期日（10月13日）。’}</p>
</blockquote>
<h3 id="6-4-智能体类型：SelfAskWithSearch"><a href="#6-4-智能体类型：SelfAskWithSearch" class="headerlink" title="6.4 智能体类型：SelfAskWithSearch"></a>6.4 智能体类型：SelfAskWithSearch</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载一个模板</span></span><br><span class="line">self_ask_prompt = hub.pull(<span class="string">&quot;hwchase17/self-ask-with-search&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(self_ask_prompt.template)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Question: Who lived longer, Muhammad Ali or Alan Turing?</p>
<p>Are follow up questions needed here: Yes.</p>
<p>Follow up: How old was Muhammad Ali when he died?</p>
<p>Intermediate answer: Muhammad Ali was 74 years old when he died.</p>
<p>Follow up: How old was Alan Turing when he died?</p>
<p>Intermediate answer: Alan Turing was 41 years old when he died.</p>
<p>So the final answer is: Muhammad Ali</p>
<p>Question: When was the founder of craigslist born?</p>
<p>Are follow up questions needed here: Yes.</p>
<p>Follow up: Who was the founder of craigslist?</p>
<p>Intermediate answer: Craigslist was founded by Craig Newmark.</p>
<p>Follow up: When was Craig Newmark born?</p>
<p>Intermediate answer: Craig Newmark was born on December 6, 1952.</p>
<p>So the final answer is: December 6, 1952</p>
<p>Question: Who was the maternal grandfather of George Washington?</p>
<p>Are follow up questions needed here: Yes.</p>
<p>Follow up: Who was the mother of George Washington?</p>
<p>Intermediate answer: The mother of George Washington was Mary Ball Washington.</p>
<p>Follow up: Who was the father of Mary Ball Washington?</p>
<p>Intermediate answer: The father of Mary Ball Washington was Joseph Ball.</p>
<p>So the final answer is: Joseph Ball</p>
<p>Question: Are both the directors of Jaws and Casino Royale from the same country?</p>
<p>Are follow up questions needed here: Yes.</p>
<p>Follow up: Who is the director of Jaws?</p>
<p>Intermediate answer: The director of Jaws is Steven Spielberg.</p>
<p>Follow up: Where is Steven Spielberg from?</p>
<p>Intermediate answer: The United States.</p>
<p>Follow up: Who is the director of Casino Royale?</p>
<p>Intermediate answer: The director of Casino Royale is Martin Campbell.</p>
<p>Follow up: Where is Martin Campbell from?</p>
<p>Intermediate answer: New Zealand.</p>
<p>So the final answer is: No</p>
<p>Question: {input}</p>
<p>Are followup questions needed here:{agent_scratchpad}</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> create_self_ask_with_search_agent</span><br><span class="line"></span><br><span class="line">tools = [</span><br><span class="line">    Tool(</span><br><span class="line">        name=<span class="string">&quot;Intermediate Answer&quot;</span>,</span><br><span class="line">        func=search.run,</span><br><span class="line">        description=<span class="string">&quot;搜素引擎&quot;</span>,</span><br><span class="line">        max_results=<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># self_ask_with_search_agent 只能传一个名为 &#x27;Intermediate Answer&#x27; 的 tool</span></span><br><span class="line">agent = create_self_ask_with_search_agent(llm, tools, self_ask_prompt)</span><br><span class="line">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=<span class="literal">True</span>, handle_parsing_errors=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">agent_executor.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;冯小刚的老婆演过哪些电影，用中文回答&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>&gt; Entering new AgentExecutor chain…Yes.</strong> <strong>Follow up: 冯小刚的老婆是谁？[‘Feng Xiaogang is a Chinese film director, screenwriter, actor, producer and politician. He is well known in China as a highly successful commercial filmmaker whose comedy films do consistently well at the</strong> <strong>box office</strong><strong>, although Feng has broken out from that mold by making some drama and period drama films.’, ‘Feng Xiaogang (冯小刚) type: Chinese film director and screenwriter.’, ‘Feng Xiaogang (冯小刚) entity_type: people.’, ‘Feng Xiaogang (冯小刚) kgmid: &#x2F;m&#x2F;04xhrq.’, ‘Feng Xiaogang (冯小刚) born: 1958 (age 66 years), Daxing District, Beijing, China.’, ‘Feng Xiaogang (冯小刚) awards: Golden Horse Award for Best Director.’, ‘Feng Xiaogang (冯小刚) children: Siyu Feng.’, ‘Feng Xiaogang (冯小刚) height: 5′ 10″.’, ‘冯小刚妻子徐帆，是内地知名女演员，文艺世家出身，1991年，24岁的她毕业于央戏表演专业。当时徐帆刚和王志文分手，很是失落，于是冯小刚时常安慰和开导她，两人 …’, ‘此外，那么爱冯小刚的徐帆，自1999年结婚至今24年都没为他生下一儿半女，反而选择领养一个小姑娘，这事儿多少也让人有点好奇。’, ‘徐帆是著名导演冯小刚的妻子，可以说是家喻户晓的实力派女星。值得一提的是，如今已然五十二岁的徐帆看上去依旧是靓丽又显年轻，整个人没有半分老态， …’, ‘1984年，经人介绍，冯小刚认识了第一任妻子。1990年，两人的亲生女儿冯思羽出生。 冯小刚的电影事业逐渐走向正轨，工作忙了起来，也结识了更多 …’, ‘不过这场婚姻并没有持续多久，随后前妻张娣为冯小刚生下一个女儿，但是冯小刚却在1993年的时候拍摄《大撒把》时又对徐帆心生爱意，两人偷偷相恋，后来在1999年 …’, ‘最佳答案: 冯小刚的现任妻子是徐帆。拓展知识：徐帆是一位著名的中国女演员，出生于1967年8月8日，毕业于中央戏剧学院表演系。她曾在多部电影和电视剧中出演重要角色，并获得..’, ‘徐帆，作为冯小刚老婆，这个女人相貌美丽，心态也非常好，对家庭非常包容，85分。冯小刚老婆85分，张艺谋老婆93分，而他的老婆我想打666分.’, ‘现在很多人知道徐帆，是因为“她是冯小刚的老婆”。 但徐帆火的时候，也一样是国民女神级别的。 她出身文艺世家，父母都是楚剧演员，家境很好。偏偏徐帆 …’, ‘2任。冯小刚一共有2任老婆2段婚姻，原配妻子是张娣。冯小刚，1958年3月18日出生于北京市大兴区，祖籍湖南省湘潭市，中国内地导演、编剧、演员。第十三届全国政协文化文史和学习 …’, ‘冯小刚第三任妻子是谁？ 冯小刚只有两任妻子，前妻是张娣，现任是徐帆。1984年，冯小刚经过单位同事的介绍与张娣相识相恋；同年，冯小刚与张娣结婚。1990年9月28日，冯小刚的 …’]Could not parse</strong> <strong>output</strong><strong>: Intermediate answer: 冯小刚的老婆是徐帆。</strong> <strong>Follow up: 徐帆演过哪些电影？</strong> Invalid or incomplete response<strong>Intermediate answer: 徐帆演过的电影包括《唐山大地震》、《一九四二》、《手机》、《不见不散》、《甲方乙方》等。</strong> <strong>So the final answer is: 徐帆演过的电影包括《唐山大地震》、《一九四二》、《手机》、《不见不散》、《甲方乙方》等。&gt; Finished chain.</strong></p>
<p>{‘input’: ‘冯小刚的老婆演过哪些电影，用中文回答’,</p>
<p> ‘output’: ‘徐帆演过的电影包括《唐山大地震》、《一九四二》、《手机》、《不见不散》、《甲方乙方》等。’}</p>
</blockquote>
<p><strong>划重点：</strong> Agent落地应用需要更多细节，后面课程中我们会专门讲 Agent 的实现</p>
<h2 id="7-LangServe"><a href="#7-LangServe" class="headerlink" title="7 LangServe"></a>7 LangServe</h2><p>LangServe 用于将 Chain 或者 Runnable 部署成一个 REST API 服务。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 LangServe</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">!pip install --upgrade <span class="string">&quot;langserve[all]&quot;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">也可以只安装一端</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">!pip install <span class="string">&quot;langserve[client]&quot;</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">!pip install <span class="string">&quot;langserve[server]&quot;</span></span></span><br></pre></td></tr></table></figure>

<h3 id="7-1-Server-端"><a href="#7-1-Server-端" class="headerlink" title="7.1 Server 端"></a>7.1 Server 端</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#!<span class="regexp">/usr/</span>bin/env pythonfrom fastapi <span class="keyword">import</span> <span class="title class_">FastAPI</span></span><br><span class="line"><span class="keyword">from</span> langchain.<span class="property">prompts</span> <span class="keyword">import</span> <span class="title class_">ChatPromptTemplate</span></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> <span class="title class_">ChatOpenAI</span></span><br><span class="line"><span class="keyword">from</span> langserve <span class="keyword">import</span> add_routes</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line">app = <span class="title class_">FastAPI</span>(</span><br><span class="line">  title=<span class="string">&quot;LangChain Server&quot;</span>,</span><br><span class="line">  version=<span class="string">&quot;1.0&quot;</span>,</span><br><span class="line">  description=<span class="string">&quot;A simple api server using Langchain&#x27;s Runnable interfaces&quot;</span>,)</span><br><span class="line"></span><br><span class="line">model = <span class="title class_">ChatOpenAI</span>()</span><br><span class="line">prompt = <span class="title class_">ChatPromptTemplate</span>.<span class="title function_">from_template</span>(<span class="string">&quot;讲一个关于&#123;topic&#125;的笑话&quot;</span>)</span><br><span class="line"><span class="title function_">add_routes</span>(</span><br><span class="line">    app,</span><br><span class="line">    prompt | model,</span><br><span class="line">    path=<span class="string">&quot;/joke&quot;</span>,)<span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.<span class="title function_">run</span>(app, host=<span class="string">&quot;localhost&quot;</span>, port=<span class="number">9999</span>)</span><br></pre></td></tr></table></figure>

<h3 id="7-2-Client-端"><a href="#7-2-Client-端" class="headerlink" title="7.2 Client 端"></a>7.2 Client 端</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">response = requests.<span class="title function_">post</span>(<span class="string">&quot;http://localhost:9999/joke/invoke&quot;</span>,</span><br><span class="line">    json=&#123;<span class="string">&#x27;input&#x27;</span>: &#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;小明&#x27;</span>&#125;&#125;)</span><br><span class="line"><span class="title function_">print</span>(response.<span class="title function_">json</span>())</span><br></pre></td></tr></table></figure>

<h2 id="8-LangChain-js"><a href="#8-LangChain-js" class="headerlink" title="8 LangChain.js"></a>8 LangChain.js</h2><p>Python 版 LangChain 的姊妹项目，都是由 Harrison Chase 主理。</p>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchainjs">https://github.com/langchain-ai/langchainjs</a></p>
<p>文档地址：<a target="_blank" rel="noopener" href="https://js.langchain.com/docs/">https://js.langchain.com/docs/</a></p>
<p>特色：</p>
<ol>
<li>可以和 Python 版 LangChain 无缝对接</li>
<li>抽象设计完全相同，概念一一对应</li>
<li>所有对象序列化后都能跨语言使用，但 API 差别挺大，不过在努力对齐</li>
</ol>
<p>支持环境：</p>
<ol>
<li>Node.js (ESM and CommonJS) - 18.x, 19.x, 20.x</li>
<li>Cloudflare Workers</li>
<li>Vercel &#x2F; Next.js (Browser, Serverless and Edge functions)</li>
<li>Supabase Edge Functions</li>
<li>Browser</li>
<li>Deno</li>
</ol>
<p>安装：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install langchain</span><br></pre></td></tr></table></figure>

<p>当前重点：</p>
<ol>
<li>追上 Python 版的能力（甚至为此做了一个基于 gpt-3.5-turbo 的代码翻译器）</li>
<li>保持兼容尽可能多的环境</li>
<li>对质量关注不多，随时间自然能解决</li>
</ol>
<h2 id="9-LangChain-与-LlamaIndex-的错位竞争"><a href="#9-LangChain-与-LlamaIndex-的错位竞争" class="headerlink" title="9 LangChain 与 LlamaIndex 的错位竞争"></a>9 LangChain 与 LlamaIndex 的错位竞争</h2><ul>
<li>LangChain 侧重与 LLM 本身交互的封装<ul>
<li>Prompt、LLM、Message、OutputParser 等工具丰富</li>
<li>在数据处理和 RAG 方面提供的工具相对粗糙</li>
<li>主打 LCEL 流程封装</li>
<li>配套 Agent、LangGraph 等智能体与工作流工具</li>
<li>另有 LangServe 部署工具和 LangSmith 监控调试工具</li>
</ul>
</li>
<li>LlamaIndex 侧重与数据交互的封装<ul>
<li>数据加载、切割、索引、检索、排序等相关工具丰富</li>
<li>Prompt、LLM 等底层封装相对单薄</li>
<li>配套实现 RAG 相关工具</li>
<li>有 Agent 相关工具，不突出</li>
</ul>
</li>
<li>LlamaIndex 为 LangChain 提供了集成<ul>
<li>在 LlamaIndex 中调用 LangChain 封装的 LLM 接口：<a target="_blank" rel="noopener" href="https://docs.llamaindex.ai/en/stable/api_reference/llms/langchain/">https://docs.llamaindex.ai/en/stable/api_reference/llms/langchain/</a></li>
<li>将 LlamaIndex 的 Query Engine 作为 LangChain Agent 的工具：<a target="_blank" rel="noopener" href="https://docs.llamaindex.ai/en/v0.10.17/community/integrations/using_with_langchain.html">https://docs.llamaindex.ai/en/v0.10.17/community/integrations/using_with_langchain.html</a></li>
<li>LangChain 也 <em>曾经</em> 集成过 LlamaIndex，目前相关接口仍在：<a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/retrievers/langchain_community.retrievers.llama_index.LlamaIndexRetriever.html">https://api.python.langchain.com/en/latest/retrievers/langchain_community.retrievers.llama_index.LlamaIndexRetriever.html</a></li>
</ul>
</li>
</ul>
<h2 id="10-总结"><a href="#10-总结" class="headerlink" title="10 总结"></a>10 总结</h2><ol>
<li>LangChain 随着版本迭代可用性有明显提升</li>
<li>使用 LangChain 要注意维护自己的 Prompt，尽量 Prompt 与代码逻辑解依赖</li>
<li>它的内置基础工具，建议充分测试效果后再决定是否使用</li>
</ol>

                
            </div>
            <hr/>

            



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2025/04/01/08-LLM-Tool/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.jpg" class="responsive-img" alt="08-LLM Tool">
                        
                        <span class="card-title">08-LLM Tool</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Tang
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/03/26/06-LlamaIndex/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/20.jpg" class="responsive-img" alt="06-LlamaIndex">
                        
                        <span class="card-title">06-LlamaIndex</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Tang
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('4'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/about" target="_blank">Tang</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;Total visits:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;Total visitors:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/TangCharlotte/AI-Classes" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:485480375@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=485480375" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 485480375" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/bu-yan-92-91" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/bu-yan-92-91" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
